# Fine tune FLAN-T5 and host on SageMaker

We want to illustrate the capability to perform multi-label classification task with generative approach. Based on research paper Scaling Instruction-Finetuned Language Models and HuggingFace implementation. 

You can switch the fine-tune dataset to generate a model for: 
* Sentiment analysis
* Text categorisation
* Tag generation  



The code is developed based on several fantastic blogs: 

[Deploy FLAN-T5 XXL on Amazon SageMaker ](https://www.philschmid.de/deploy-flan-t5-sagemaker) from HuggingFace

[Fine-tune FLAN-T5 XL/XXL using DeepSpeed & Hugging Face Transformers](https://www.philschmid.de/fine-tune-flan-t5-deepspeed) from HuggingFace

[Combine Amazon SageMaker and DeepSpeed to fine-tune FLAN-T5 XXL](https://www.philschmid.de/sagemaker-deepspeed) from HuggingFace
